# llm_utils.py (Version finale avec architecture en 2 appels)
import json
import os
from openai import OpenAI, RateLimitError, APIError
import streamlit as st
from pydantic import BaseModel, ValidationError
from typing import List, Optional

import data_utils  # Pour les utilitaires de code NAF
import rag_utils  # Pour l'int√©gration RAG

# --- CONFIGURATION ---
OPENROUTER_API_KEY = st.secrets.get("OPENROUTER_API_KEY", os.environ.get("OPENROUTER_API_KEY"))

HTTP_REFERER = os.environ.get("LLM_HTTP_REFERER", "https://recherche-job-par-candidature-spontanee.streamlit.app/")
X_TITLE = os.environ.get("LLM_X_TITLE", "Streamlit Job Search App")
LLM_MODEL = "google/gemma-3-27b-it:free" 

# --- MOD√àLE PYDANTIC POUR LA R√âPONSE LLM ---
class LLMSuggestionOutput(BaseModel):
    developed_text: Optional[str] = None
    naf_sections: Optional[List[str]] = []
    naf_specific_codes: Optional[List[str]] = []
    effectifs_codes: Optional[List[str]] = []


# --- FONCTION HELPER POUR LA VALIDATION ET LE R√âSUM√â ---
def _validate_and_summarize_llm_response(
    llm_response_data: LLMSuggestionOutput,
    naf_sections_config: dict,
    effectifs_groupes_config: dict,
    all_specific_naf_codes: list,
    naf_detailed_lookup_for_libelles: dict,
    effectifs_tranches_map_for_summary: dict
) -> tuple[dict | None, str | None]:
    """
    Valide la r√©ponse pars√©e du LLM, la nettoie et cr√©e un r√©sum√© lisible.
    Cette fonction est une refactorisation de votre logique de validation originale.
    """
    validated_suggestions = {
        "naf_sections": [],
        "naf_specific_codes": [],
        "effectifs_codes": []
    }

    # Valider les sections NAF
    if llm_response_data.naf_sections:
        valid_naf_section_keys = naf_sections_config.keys()
        validated_suggestions["naf_sections"] = [
            s.upper() for s in llm_response_data.naf_sections if s.upper() in valid_naf_section_keys
        ]

    # Valider les codes NAF sp√©cifiques
    if llm_response_data.naf_specific_codes and all_specific_naf_codes:
        valid_specific_codes_master_set = set(s.upper() for s in all_specific_naf_codes if isinstance(s, str))
        temp_specific_codes = []
        for code_suggestion_str in llm_response_data.naf_specific_codes:
            if not isinstance(code_suggestion_str, str) or not code_suggestion_str.strip():
                continue
            code_to_validate = code_suggestion_str.strip().upper()
            if code_to_validate in valid_specific_codes_master_set:
                temp_specific_codes.append(code_to_validate)
        validated_suggestions["naf_specific_codes"] = list(set(temp_specific_codes))

    # Valider les codes d'effectifs
    if llm_response_data.effectifs_codes:
        all_valid_effectifs_codes = set()
        for group_details in effectifs_groupes_config.values():
            all_valid_effectifs_codes.update(group_details.get("codes", []))
        validated_suggestions["effectifs_codes"] = [
            e for e in llm_response_data.effectifs_codes if e in all_valid_effectifs_codes
        ]

    # Validation crois√©e : s'assurer que les codes sp√©cifiques appartiennent aux sections sugg√©r√©es
    if validated_suggestions["naf_sections"] and validated_suggestions["naf_specific_codes"]:
        codes_to_keep = [
            code for code in validated_suggestions["naf_specific_codes"]
            if data_utils.get_section_for_code(code) in validated_suggestions["naf_sections"]
        ]
        if len(codes_to_keep) < len(validated_suggestions["naf_specific_codes"]):
            print(f"LLM WARNING: Certains codes NAF sp√©cifiques ont √©t√© retir√©s car ils ne correspondaient pas aux sections sugg√©r√©es.")
        validated_suggestions["naf_specific_codes"] = codes_to_keep

    # Si rien n'est valid√©, retourner None
    if not any(validated_suggestions.values()):
        return None, "L'IA n'a pas pu extraire de crit√®res pertinents ou coh√©rents."

    # Construire le r√©sum√© lisible
    summary_parts = []
    if llm_response_data.developed_text and llm_response_data.developed_text.strip():
        summary_parts.append(f"**Analyse de l'IA :**\n_{llm_response_data.developed_text.strip()}_")
        summary_parts.append("\n**Crit√®res sugg√©r√©s et valid√©s :**")
    else:
        summary_parts.append("**L'IA a sugg√©r√© et valid√© les crit√®res suivants :**")

    if validated_suggestions["naf_sections"]:
        section_descs = [f"_{sc} ({naf_sections_config.get(sc, {}).get('description', sc)})_" for sc in validated_suggestions["naf_sections"]]
        summary_parts.append(f"üîç **Secteurs NAF :** {', '.join(section_descs)}")

    if validated_suggestions["naf_specific_codes"]:
        specific_code_descs = [f"_{code} ({naf_detailed_lookup_for_libelles.get(code, 'Libell√© inconnu')})_" for code in validated_suggestions["naf_specific_codes"]]
        summary_parts.append(f"üè∑Ô∏è **Codes NAF sp√©cifiques :** {', '.join(specific_code_descs)}")

    if validated_suggestions["effectifs_codes"]:
        effectif_descs = [f"_{effectifs_tranches_map_for_summary.get(code, code)} (code: {code})_" for code in validated_suggestions["effectifs_codes"]]
        summary_parts.append(f"üë• **Tranches d'effectifs :** {', '.join(effectif_descs)}")

    human_readable_summary = "\n\n".join(summary_parts)

    return validated_suggestions, human_readable_summary


# --- FONCTION D'APPEL N¬∞1 : Le "Brainstormer" ---
def _get_brainstormed_domains(user_text_prompt: str, client: OpenAI) -> tuple[list[str], str | None]:
    """
    Premier appel LLM pour brainstormer les types d'entreprises en langage naturel.
    """
    system_prompt_brainstorm = """
    Vous √™tes un conseiller d'orientation expert. Votre unique mission est d'analyser la description d'un m√©tier ou d'un projet professionnel.
    En r√©ponse, listez de mani√®re concise sous forme de puces les types d'entreprises ou de secteurs d'activit√©s concrets o√π cette personne pourrait travailler.
    Ne vous souciez pas des codes NAF. Soyez descriptif. Ne fournissez aucune phrase d'introduction ou de conclusion, juste la liste √† puces.

    Exemple de demande : "Je suis d√©veloppeur web."
    Votre r√©ponse attendue :
    - Entreprises de services du num√©rique (ESN)
    - Agences web et de communication
    - √âditeurs de logiciels
    - Startups technologiques
    - Le d√©partement informatique de grandes entreprises
    - Conseil en syst√®mes et logiciels informatiques
    """
    try:
        completion = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt_brainstorm},
                {"role": "user", "content": user_text_prompt}
            ],
            temperature=0.5,
        )
        response_text = completion.choices[0].message.content
        domains = []
        if response_text: # Ensure response_text is not None
            for line in response_text.split('\n'):
                stripped_line = line.strip()
                if stripped_line.startswith("- ") or stripped_line.startswith("* "):
                    domains.append(stripped_line.lstrip("-* ").strip())
        return domains, response_text
    except Exception as e:
        print(f"LLM Brainstorming Error: {e}")
        return [], None

# --- ORCHESTRATEUR PRINCIPAL ---
def get_llm_suggestions(
    user_text_prompt: str,
    naf_sections_config: dict,
    effectifs_groupes_config: dict,
    all_specific_naf_codes: list = None,
    naf_detailed_lookup_for_libelles: dict = None,
    effectifs_tranches_map_for_summary: dict = None,
    rag_model=None,
    rag_index=None,
    rag_codes_map=None
) -> tuple[dict | None, str | None]:
    """
    Orchestre le processus en 2 appels LLM pour g√©n√©rer des suggestions pr√©cises.
    """
    if not OPENROUTER_API_KEY:
        st.error("Cl√© API OpenRouter non configur√©e.")
        return None, None

    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY,
        default_headers={"HTTP-Referer": HTTP_REFERER, "X-Title": X_TITLE}
    )

    # === √âTAPE 1: APPEL LLM N¬∞1 - Le "Brainstormer" ===
    with st.spinner("Analyse du m√©tier et des secteurs potentiels... (√âtape 1/3)"):
        brainstormed_domains, raw_brainstorm_response = _get_brainstormed_domains(user_text_prompt, client)


    if not brainstormed_domains:
        log_message = f"LLM Brainstorming Warning: Aucun domaine d'activit√© identifi√© pour la requ√™te utilisateur : '{user_text_prompt}'."
        if raw_brainstorm_response:
            log_message += f"\nR√©ponse brute du LLM (Brainstormer) :\n---\n{raw_brainstorm_response}\n---"
        print(log_message)
        st.warning("L'IA n'a pas pu identifier de domaines d'activit√©. Essayez de reformuler votre demande.")
        return None, None
    
    print(f"Domaines brainstorm√©s par l'IA : {brainstormed_domains}")

    # === √âTAPE 2: LE "MATCHER" - Recherche RAG en boucle ===
    with st.spinner("Recherche des codes NAF correspondants... (√âtape 2/3)"):
        relevant_naf_codes_set = set()
        for domain in brainstormed_domains:
            codes_from_rag = rag_utils.find_relevant_naf_codes(
                query=domain, model=rag_model, index=rag_index, codes_mapping=rag_codes_map, k=5
            )
            relevant_naf_codes_set.update(codes_from_rag)
    
    final_naf_codes_list = sorted(list(relevant_naf_codes_set))
    if not final_naf_codes_list:
        st.warning("Aucun code NAF sp√©cifique trouv√© pour les domaines identifi√©s.")
        return None, None
    print(f"Codes NAF pertinents trouv√©s via RAG : {final_naf_codes_list}")

    # === √âTAPE 3: APPEL LLM N¬∞2 - Le "Synth√©tiseur" ===
    with st.spinner("Synth√®se des suggestions finales... (√âtape 3/3)"):
        prompt_naf_sections = {key: details["description"] for key, details in naf_sections_config.items()}
        prompt_effectifs_groups = {group_key: {"label": details["label"], "codes": details["codes"]} for group_key, details in effectifs_groupes_config.items()}

        system_prompt_synthesize = f"""
        Vous √™tes un assistant expert qui finalise une recherche de crit√®res d'emploi.
        Votre mission est de synth√©tiser les informations fournies pour g√©n√©rer un objet JSON final.

        CONTEXTE FOURNI :
        1. Requ√™te initiale de l'utilisateur : "{user_text_prompt}"
        2. Domaines d'activit√©s pertinents identifi√©s : {json.dumps(brainstormed_domains, ensure_ascii=False)}
        3. Liste de codes NAF sp√©cifiques pertinents trouv√©s : {json.dumps(final_naf_codes_list, ensure_ascii=False)}

        VOTRE T√ÇCHE :
        1.  **Choisir les codes NAF sp√©cifiques** : √Ä partir de la "Liste de codes NAF sp√©cifiques pertinents trouv√©s", s√©lectionnez les plus appropri√©s pour la requ√™te de l'utilisateur.
        2.  **D√©duire les sections NAF** : D√©duisez les sections NAF (lettres) √† partir des codes sp√©cifiques que vous avez choisis.
        3.  **Sugg√©rer les effectifs** : Sugg√©rez les tranches d'effectifs pertinentes. Excluez par d√©faut les TPE (<10 salari√©s) sauf si la requ√™te initiale le sugg√®re explicitement (startup, freelance, etc.).
        En vous basant sur la requ√™te utilisateur et les `Groupes d'effectifs disponibles` (fournis en JSON dans le prompt syst√®me global sous `prompt_effectifs_groups`), s√©lectionnez les codes d'effectifs appropri√©s.
            - Pour une description de poste g√©n√©rale (exemples: "horticulteur", "d√©veloppeur web"), votre s√©lection doit typiquement inclure les cat√©gories pour PME (codes "11", "12", "21", "22"), ETI/Grandes Entreprises (codes "31", "32", "41", "42", "51", "52", "53"), ET AUSSI "Unit√©s non-employeuses" (code "NN", pour couvrir les ind√©pendants).
            - Si la requ√™te utilisateur mentionne explicitement des termes comme "startup", "petite structure", "artisan", "commerce de proximit√©", alors AJOUTEZ les TPE (codes "01", "02", "03") √† votre s√©lection pr√©c√©dente.
            - Si la requ√™te est tr√®s cibl√©e sur "freelance", "consultant ind√©pendant", "auto-entrepreneur", alors "Unit√©s non-employeuses" ("NN") est le plus pertinent, potentiellement accompagn√© des TPE.
            Assurez-vous que les codes retourn√©s dans `effectifs_codes` correspondent aux cat√©gories que vous avez jug√©es pertinentes.
        4.  **R√©diger un texte de synth√®se** (`developed_text`) : R√©digez un court texte qui explique votre raisonnement final (y compris pour les effectifs) en vous basant sur le contexte fourni.

        R√âF√âRENCES (√† utiliser pour valider vos choix) :
        - Sections NAF disponibles : {json.dumps(prompt_naf_sections, indent=2, ensure_ascii=False)}
        - Groupes d'effectifs disponibles : {json.dumps(prompt_effectifs_groups, indent=2, ensure_ascii=False)}
        
        FORMAT DE SORTIE :
        Retournez UNIQUEMENT l'objet JSON final. Ne mettez aucun commentaire.
        ```json
        {{
          "developed_text": "TEXTE DE SYNTH√àSE JUSTIFIANT LES CHOIX FINALS.",
          "naf_sections": ["LISTE_DES_LETTRES_DE_SECTION_NAF"],
          "naf_specific_codes": ["LISTE_FINALE_DES_CODES_NAF_SPECIFIQUES"],
          "effectifs_codes": ["LISTE_DES_CODES_DE_TRANCHES_EFFECTIFS"]
        }}
        ```
        """
        try:
            completion = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[{"role": "system", "content": system_prompt_synthesize}],
                response_format={"type": "json_object"}
            )
            response_content = completion.choices[0].message.content
            
            # Valider la structure de la r√©ponse avec Pydantic
            llm_response_data = LLMSuggestionOutput.model_validate_json(response_content)
            
            # Utiliser la fonction helper pour valider le contenu et cr√©er le r√©sum√©
            return _validate_and_summarize_llm_response(
                llm_response_data,
                naf_sections_config,
                effectifs_groupes_config,
                all_specific_naf_codes,
                naf_detailed_lookup_for_libelles,
                effectifs_tranches_map_for_summary
            )

        except (RateLimitError, APIError, ValidationError, json.JSONDecodeError) as e:
            error_message = f"Une erreur est survenue lors de la phase de synth√®se de l'IA : {e}"
            st.error(error_message)
            print(f"LLM Synthesis Error: {e}")
            import traceback
            print(traceback.format_exc())
            return None, None
        except Exception as e:
            st.error(f"Une erreur inattendue est survenue : {e}")
            import traceback
            print(f"Unexpected LLM Error: {e}\n{traceback.format_exc()}")
            return None, None